{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 1"
      ],
      "metadata": {
        "id": "4ZxJInvh9Efm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â€¢ Modify the algorithm so that substitution operation cost depends on the\n",
        "key proximity on QWERTY keyboard."
      ],
      "metadata": {
        "id": "zB7GCj6k9NGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dictionary(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return [line.strip() for line in file]"
      ],
      "metadata": {
        "id": "2BId14f-9-XU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "x9f5iPaSxPov"
      },
      "outputs": [],
      "source": [
        "keyboard_layout = {\n",
        "    'q': (0, 0), 'w': (0, 1), 'e': (0, 2), 'r': (0, 3), 't': (0, 4), 'y': (0, 5), 'u': (0, 6), 'i': (0, 7), 'o': (0, 8), 'p': (0, 9),\n",
        "    'a': (1, 0), 's': (1, 1), 'd': (1, 2), 'f': (1, 3), 'g': (1, 4), 'h': (1, 5), 'j': (1, 6), 'k': (1, 7), 'l': (1, 8),\n",
        "    'z': (2, 0), 'x': (2, 1), 'c': (2, 2), 'v': (2, 3), 'b': (2, 4), 'n': (2, 5), 'm': (2, 6)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proximity_matrix = {}\n",
        "for key1, coord1 in keyboard_layout.items():\n",
        "    proximity_matrix[key1] = {}\n",
        "    for key2, coord2 in keyboard_layout.items():\n",
        "        proximity_matrix[key1][key2] = ((coord1[0] - coord2[0]) ** 2 + (coord1[1] - coord2[1]) ** 2) ** 0.5\n",
        "\n"
      ],
      "metadata": {
        "id": "1xgxfEDu9SxP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wagner_fischer(s1, s2):\n",
        "    len_s1, len_s2 = len(s1), len(s2)\n",
        "    if len_s1 > len_s2:\n",
        "        s1, s2 = s2, s1\n",
        "        len_s1, len_s2 = len_s2, len_s1\n",
        "\n",
        "    current_row = range(len_s1 + 1)\n",
        "    for i in range(1, len_s2 + 1):\n",
        "        previous_row, current_row = current_row, [i] + [0] * len_s1\n",
        "        for j in range(1, len_s1 + 1):\n",
        "            add, delete, change = previous_row[j] + 1, current_row[j-1] + 1, previous_row[j-1]\n",
        "            if s1[j-1] != s2[i-1]:\n",
        "                substitution_cost = proximity_matrix.get(s1[j-1], {}).get(s2[i-1], float('inf'))\n",
        "                change += substitution_cost\n",
        "            current_row[j] = min(add, delete, change)\n",
        "\n",
        "    return current_row[len_s1]"
      ],
      "metadata": {
        "id": "k_H9xr_-9i3i"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spell_check(word, dictionary):\n",
        "    suggestions = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        distance = wagner_fischer(word, correct_word)\n",
        "        suggestions.append((correct_word, distance))\n",
        "\n",
        "    suggestions.sort(key=lambda x: x[1])\n",
        "    return suggestions[:10]"
      ],
      "metadata": {
        "id": "wpXf-vGT9nfx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = load_dictionary(\"words.txt\")\n",
        "misspelled_word = \"wrlod\"\n",
        "suggestions = spell_check(misspelled_word, dictionary)\n",
        "print(f\"Top 10 suggestions for '{misspelled_word}':\")\n",
        "for word, distance in suggestions:\n",
        "    print(f\"{word} (Distance: {distance})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XNH8sNZ-G5p",
        "outputId": "24110075-0894-4d28-ae40-9b76e5bd22de"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 suggestions for 'wrlod':\n",
            "world (Distance: 2)\n",
            "wood (Distance: 2.0)\n",
            "rod (Distance: 2)\n",
            "well (Distance: 3.0)\n",
            "food (Distance: 3.0)\n",
            "road (Distance: 3)\n",
            "word (Distance: 3)\n",
            "wed (Distance: 3.0)\n",
            "los (Distance: 3.0)\n",
            "wrote (Distance: 3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another modification: include transposition operation, so that you compute\n",
        "a Damerau-Levenshtein distance"
      ],
      "metadata": {
        "id": "a3m15-jI_jTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dictionary(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "def wagner_fischer(s1, s2):\n",
        "    len_s1, len_s2 = len(s1), len(s2)\n",
        "    if len_s1 > len_s2:\n",
        "        s1, s2 = s2, s1\n",
        "        len_s1, len_s2 = len_s2, len_s1\n",
        "\n",
        "    max_dist = len_s1 + 1\n",
        "    distances = [[0] * (len_s2 + 1) for _ in range(2)]\n",
        "    for i in range(len_s1 + 1):\n",
        "        distances[0][i] = i\n",
        "\n",
        "    for i in range(1, len_s2 + 1):\n",
        "        distances[i % 2][0] = i\n",
        "        for j in range(1, len_s1 + 1):\n",
        "            add, delete, change = distances[(i - 1) % 2][j] + 1, distances[i % 2][j - 1] + 1, distances[(i - 1) % 2][j - 1]\n",
        "            if s1[j - 1] != s2[i - 1]:\n",
        "                change += 1\n",
        "            distances[i % 2][j] = min(add, delete, change)\n",
        "            if i > 1 and j > 1 and s1[j - 1] == s2[i - 2] and s1[j - 2] == s2[i - 1]:\n",
        "                distances[i % 2][j] = min(distances[i % 2][j], distances[(i - 2) % 2][j - 2] + 1)\n",
        "\n",
        "    return distances[len_s2 % 2][len_s1]\n",
        "\n",
        "def spell_check(word, dictionary):\n",
        "    suggestions = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        distance = wagner_fischer(word, correct_word)\n",
        "        suggestions.append((correct_word, distance))\n",
        "\n",
        "    suggestions.sort(key=lambda x: x[1])\n",
        "    return suggestions[:10]\n",
        "\n",
        "# Example Usage\n",
        "dictionary = load_dictionary(\"words.txt\")\n",
        "misspelled_word = \"wrllod\"\n",
        "suggestions = spell_check(misspelled_word, dictionary)\n",
        "print(f\"Top 10 suggestions for '{misspelled_word}':\")\n",
        "for word, distance in suggestions:\n",
        "    print(f\"{word} (Distance: {distance})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu54ETFn_f0_",
        "outputId": "f23014af-2ed7-48e4-e975-fd7028df6e1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 suggestions for 'wrllod':\n",
            "willow (Distance: 2)\n",
            "will (Distance: 3)\n",
            "would (Distance: 3)\n",
            "world (Distance: 3)\n",
            "well (Distance: 3)\n",
            "called (Distance: 3)\n",
            "yellow (Distance: 3)\n",
            "follow (Distance: 3)\n",
            "allow (Distance: 3)\n",
            "blood (Distance: 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2"
      ],
      "metadata": {
        "id": "t6S1wJSfEdNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "nltk.download('gutenberg')\n",
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cu2jRMvqP2JO",
        "outputId": "8e8ad2c8-3de8-440b-e61e-eabc61760929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocabulary(corpus):\n",
        "    words = [word.lower() for word in corpus if word.isalpha()]  # Ensure words are alphanumeric\n",
        "    vocabulary = set(words)\n",
        "    return vocabulary"
      ],
      "metadata": {
        "id": "EfrdmtGTP8Wy"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_word_counts(document):\n",
        "    word_counts = Counter(document)\n",
        "    return word_counts"
      ],
      "metadata": {
        "id": "BYAdLpG-P_nD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_to_vector(document, vocabulary):\n",
        "    vector = np.zeros(len(vocabulary))\n",
        "    word_counts = calculate_word_counts(document)\n",
        "    for i, word in enumerate(vocabulary):\n",
        "        vector[i] = word_counts[word]\n",
        "    return vector"
      ],
      "metadata": {
        "id": "6iJ4y_k2QBrV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dot_product(vector1, vector2):\n",
        "    return np.dot(vector1, vector2)"
      ],
      "metadata": {
        "id": "MfqNDoYjQDYk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))"
      ],
      "metadata": {
        "id": "ufLsDxhQQIT0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = create_vocabulary(text)"
      ],
      "metadata": {
        "id": "XqQVAb1yRkh9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document1 = text[:500]\n",
        "document2 = text[500:1000]"
      ],
      "metadata": {
        "id": "FVe4zgPTQ4gU"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector1 = map_to_vector(document1, vocabulary)\n",
        "vector2 = map_to_vector(document2, vocabulary)\n"
      ],
      "metadata": {
        "id": "CcDqOTxCRrd1"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = compute_dot_product(vector1, vector2)"
      ],
      "metadata": {
        "id": "aXWvW2yJRr_H"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity between documents:\", similarity)"
      ],
      "metadata": {
        "id": "Apid3r8rRwqF",
        "outputId": "1d90672b-c916-48e0-e655-86b86b1c388c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between documents: 937.0\n"
          ]
        }
      ]
    }
  ]
}